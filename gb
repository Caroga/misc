#!/bin/bash
# Copyright (c) 2012 fbt <fbt@fleshless.org>
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#   - Redistributions of source code must retain the above copyright notice, 
#       this list of conditions and the following disclaimer.
#   - Redistributions in binary form must reproduce the above copyright notice,
#       this list of conditions and the following disclaimer in the
#       documentation and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR
# IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
# FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER
# IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
# OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#
# About:
# Gelbooru/Danbooru downloader
# I am using the official APIs for this one:
# http://gelbooru.com/index.php?page=help&topic=dapi
# http://danbooru.donmai.us/help/api

limit='100'
action='list'
api_type='gelbooru'
cookies_file="$HOME/.cookies"

curl_version=`curl -V | head -1`
useragent="Booru API tool ($curl_version)"
curl_args="-sL"

gbrc="$HOME/.gbrc"

while getopts "DGdvtlfe:" option; do
	case "$option" in
		D) api_type='danbooru';;
		G) api_type='gelbooru';;

		l) action='list';;
		d) action='download';;
		v) curl_args="$curl_args -vvvv";;

		f) force_download='1';; 

		t) archive='1';;
		e) email="$OPTARG";;
	esac
done

[[ "$OPTIND" ]] && { shift $((OPTIND-1)); }

tags="$1"

trap "rm md5sums" EXIT

case "$api_type" in
	danbooru)
		echo "Danbooru \"public\" API requires you to log in."

		[[ -f "$gbrc" ]] && { source "$gbrc"; }

		[[ "$danbooru_username" ]] || { read -p "Username: " danbooru_username; }
		[[ "$danbooru_pwhash" ]] || {
			read -sp "Password for ${danbooru_username}: " danbooru_password; echo
			danbooru_pwhash=`echo -n "choujin-steiner--${danbooru_password}--" | sha1sum | awk '{print $1}'`
		}

		[[ -f "$gbrc" ]] || {
			read -p 'Do you wish to save your danbooru login credentials? The password will be encoded [y/N] ' ans
			[[ "$ans" == 'y' ]] && {
				echo -e "danbooru_username='${danbooru_username}'\ndanbooru_pwhash='${danbooru_pwhash}'" > "$gbrc"
			}
		}

		api_base_url="http://danbooru.donmai.us/post/index.xml?login=${danbooru_username}&password_hash=${danbooru_pwhash}&"
		posts_request="${api_base_url}tags=${tags}&limit=${limit}&page="

		first_page='1'
	;;

	gelbooru)
		api_base_url="http://gelbooru.com/index.php?page=dapi&s=post&q=index&"
		posts_request="${api_base_url}tags=${tags}&limit=${limit}&pid="

		first_page='0'
	;;
esac

post_count=`curl $curl_args -A "$useragent" "${api_base_url}tags=${tags}&limit=1" \
	| grep "posts count" | sed -E "s/.*count=\"([^ ]+)\".*/\1/"`
query_count="$(( (post_count/limit)+1 ))"

for i in `seq "$first_page" "$query_count"`; do
#	posts=`curl $curl_args -A "$useragent" "${posts_request}$((i-1))" | sed -Ee "s/>/>\r\n/g" | grep "post "`
	posts=( `curl $curl_args -A "$useragent" "${posts_request}$((i))" | sed -Ee "s/>/>\r\n/g" | grep "post " | sed -E "s/\"\s/\"\r\n/g" | grep "file_url=" | sed -E "s/.*file_url=\"(.*)\".*/\1/"` )
	[[ "$force_download" ]] || find . -maxdepth 1 -mindepth 1 -type f | while read line; do md5sum "$line" | awk '{print $1}'; done > md5sums

#	echo "${posts_request}$((i))"

#	echo "${posts}" | while read line; do
	for p in "${posts[@]}"; do
#		post_data="$line"
#		post_file=`echo "${post_data}" | sed -E "s/\"\s/\"\r\n/g" | grep "file_url=" | sed -E "s/.*file_url=\"(.*)\".*/\1/"`
		post_file="$p"

		case "$action" in
			download)
				unset file_skip

				[[ "$gb_counter" ]] || { gb_counter='1'; }

				echo -ne "${post_file}		[${gb_counter}/${post_count}]"
				post_file_hash=${post_file##*/}; post_file_hash=${post_file_hash%%.*}

				[[ "$force_download" ]] || {
					grep "$post_file_hash" md5sums &>/dev/null && { file_skip='1'; }
				}

				[[ "$file_skip" ]] && {
					echo -ne " (skip)"
				} || {
					wget -cq "${post_file}"
				}

				echo

				gb_counter=$((gb_counter+1))
			;;

			list)
				echo "${post_file}"
			;;
		esac
	done
done

[[ "$action" == "download" ]] && { echo; }

[[ "$archive" ]] && {
	tar czf "gb-${tags/ /}.tgz" *
}
